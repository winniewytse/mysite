{
  "articles": [
    {
      "path": "blog.html",
      "title": "WT Blog",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2024-11-11T12:16:58-08:00"
    },
    {
      "path": "hcbr.html",
      "title": "Bayesian Approach fo Classical Power Analysis (BAC Power)",
      "description": "Addressing uncertainty by integrating prior information and theoretical insights for power analysis\n",
      "author": [
        {
          "name": "Winnie Wing-Yee Tse",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\nView App in Full\n\n\n\n\n\n\n",
      "last_modified": "2024-11-11T12:16:58-08:00"
    },
    {
      "path": "index.html",
      "title": "Personal Website",
      "author": [],
      "contents": "\n\n\nWinnie Wing-Yee Tse\n\n\n\n\n\n\nCV\n\n\n\n\n\n\nAbout Me\n\nI earned my Ph.D.Â in Quantitative Methods and Computational Psychology at the University of Southern California (USC) in August 2024. Currently, I am working as a psychometrician at Vretta Inc., providing psychometric services to K-12 assessments in Canada.\n\n\n\nEducation\n\nPhD in Quantitative Methods and Computational Psychology, 2024\nUniversity of Southern California\n\nMA in Quantitative Methods and Computational Psychology, 2021\nUniversity of Southern California\n\nBA in Psychology, 2018\nUniversity of British Columbia\n\n\n\n\nResearch Interests\n\nPsychometrics\nStructural Equation Modeling\nMultilevel Modeling\nBayesian Statistics\n\n\n\nMore about my research\n\n\n\n\n\n\n",
      "last_modified": "2024-11-11T12:16:58-08:00"
    },
    {
      "path": "research.html",
      "title": "Current Research Projects",
      "author": [
        {
          "name": "Winnie Wing-Yee Tse",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\nIncoporting Uncertainty to Sample Size Planning in Multilevel Studies\nStandard sample size planning software (e.g., G*Power, PowerUpR) requires an input of parameter values. However, in the study design phase, the parameter values, such as effect size, are by definition unknown. While providing our best educated guess is a common practice, ignoring uncertainty can lead to erroneous sample size calculation. The effect of ignoring uncertainty can exacerbate in multilevel studies, which involve additional parameters, such as intraclass correlation. What should researchers do to address uncertainty about parameter values in sample size planning?\nMy research develops a hybrid-classical Bayesian (HCB) approach that incorporates uncertainty to sample size planning in multilevel studies. The HCB approach allows researchers to specify no only their best educated guess of the parameter values, but also their uncertainty about those values. This approach realistically calculate the sample size needed in the new study and appropriately control power at the desired level.\nMultilevel Regression and Poststratification on Social Media Data\nPrediction of subnational outcomes (e.g., number of covid cases in a county) using language features on social media (e.g., positive emotions and health) has become increasingly popular in psychological research. This task often encounters two major challenges: (a) social media samples are skewed toward certain subgroups, leading to nonrepresentative prediction, and (b) aggregating individual-level textual features at the county level can result in erroneous predictions. Therefore, my research team proposes using (a) postratification, which adjusts the weight of the textual features according to the proportion of the subgroups in the population, to address nonrepresentativeness, and (b) multilevel modeling, which accounts for the hierarchical structure of social media data (e.g., tweets nested within users nested within counties), to address issues with aggregation.\nMeasurement Invariance on Psychological Scales with Ordered Categorical Items\nPsychological scales are often used to measure latent traits, such as personality and beliefs. For valid group comparisons of composite (i.e., sum or mean) scores of a scale, measurement invariance is a prerequisite, which ensures the scale measures the latent traits equivalently across groups. In general, there are four levels of measurement invariance: configural, metric, scalar, and strict. Strict invariance is least often to be tested in practice, because scalar invariance allows valid use of composite scores for scales with continuous items. In my research, I evaluate whether scalar invariance supports valid use of composite scores for scales with ordered-categorical items and provide guidelines on the requirements under different conditions.\n\n\n\n",
      "last_modified": "2024-11-11T12:16:59-08:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
